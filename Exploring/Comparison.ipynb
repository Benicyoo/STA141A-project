{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a67896ac-686c-4907-9f5c-3ded59e7a1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "2\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "4\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "7\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "8\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "9\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "11\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "12\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "13\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "14\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "15\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "16\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "17\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "18\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "19\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "21\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "22\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "23\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "24\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "26\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "27\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "28\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "29\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "31\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "33\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "34\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "35\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "36\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "37\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "38\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "39\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "40\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "41\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "42\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "43\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "44\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "45\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "46\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "48\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "49\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "51\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "52\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "53\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "54\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "55\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "56\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "57\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "58\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "59\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "61\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "62\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "63\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "64\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "65\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "66\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "67\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "68\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "69\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "70\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "71\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "72\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "73\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "74\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "76\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "77\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "78\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "79\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "80\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "81\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "82\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "83\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "84\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "85\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "86\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "87\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "88\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "89\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "90\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "91\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "92\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "93\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "94\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "95\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "96\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "97\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "98\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "99\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "101\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "102\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "103\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "104\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "105\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "106\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "107\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "108\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "109\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "111\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "112\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "113\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "114\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "115\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "116\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "117\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "119\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "120\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "121\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "122\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "123\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "124\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "125\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "126\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "127\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "128\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "129\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "130\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "131\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "132\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "133\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "134\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "135\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "136\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "137\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "138\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "139\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "140\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "141\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "142\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "143\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "144\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "145\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "146\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "147\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "148\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "149\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "151\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "152\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "153\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "154\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "155\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "156\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "157\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "158\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "159\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "160\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "161\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "162\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "163\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "164\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "165\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "166\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "167\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "168\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "169\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "170\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "171\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "172\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "173\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "174\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "175\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "176\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "177\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "178\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "179\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "180\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "181\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "182\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "183\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "184\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "185\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "186\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "188\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "189\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "190\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "191\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "192\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "193\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "194\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "195\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "196\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "197\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "198\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "199\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "ANN is better 0.9940476190476191\n",
      "RF vs. ANN: 0.974537037037037 vs 0.9940476190476191\n",
      "RF is better 0.9885668276972625\n",
      "RF vs. ANN: 0.9885668276972625 vs 0.9791666666666666\n",
      "ANN is better 0.9970238095238095\n",
      "RF vs. ANN: 0.9827702702702702 vs 0.9970238095238095\n",
      "RF is better 0.9939338235294117\n",
      "RF vs. ANN: 0.9939338235294117 vs 0.9801587301587301\n",
      "ANN is better 0.9953703703703703\n",
      "RF vs. ANN: 0.984848484848485 vs 0.9953703703703703\n",
      "RF is better 0.9912253694581281\n",
      "RF vs. ANN: 0.9912253694581281 vs 0.9788359788359788\n",
      "RF is better 0.9934121621621621\n",
      "RF vs. ANN: 0.9934121621621621 vs 0.984457671957672\n",
      "RF is better 0.9929667519181585\n",
      "RF vs. ANN: 0.9929667519181585 vs 0.9904100529100529\n",
      "ANN is better 0.998015873015873\n",
      "RF vs. ANN: 0.9925675675675676 vs 0.998015873015873\n",
      "RF is better 1.0\n",
      "RF vs. ANN: 1.0 vs 0.9920634920634921\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.997229916897507 vs 0.9990079365079365\n",
      "ANN is better 0.9937169312169312\n",
      "RF vs. ANN: 0.9862689393939394 vs 0.9937169312169312\n",
      "ANN is better 0.9933862433862434\n",
      "RF vs. ANN: 0.9839743589743589 vs 0.9933862433862434\n",
      "RF is better 0.992482459071166\n",
      "RF vs. ANN: 0.992482459071166 vs 0.9828042328042328\n",
      "ANN is better 0.9976851851851852\n",
      "RF vs. ANN: 0.976923076923077 vs 0.9976851851851852\n",
      "RF is better 0.9953224189776143\n",
      "RF vs. ANN: 0.9953224189776143 vs 0.9831349206349206\n",
      "ANN is better 0.9867724867724869\n",
      "RF vs. ANN: 0.9728185595567868 vs 0.9867724867724869\n",
      "ANN is better 0.9973544973544974\n",
      "RF vs. ANN: 0.9906881313131313 vs 0.9973544973544974\n",
      "RF is better 0.9898550724637681\n",
      "RF vs. ANN: 0.9898550724637681 vs 0.974537037037037\n",
      "RF is better 0.9952651515151515\n",
      "RF vs. ANN: 0.9952651515151515 vs 0.9933862433862435\n",
      "RF is better 0.9974358974358973\n",
      "RF vs. ANN: 0.9974358974358973 vs 0.9966931216931216\n",
      "ANN is better 0.9957010582010581\n",
      "RF vs. ANN: 0.990009826400262 vs 0.9957010582010581\n",
      "RF is better 0.9945299145299145\n",
      "RF vs. ANN: 0.9945299145299145 vs 0.986111111111111\n",
      "ANN is better 0.9976851851851851\n",
      "RF vs. ANN: 0.98747076511861 vs 0.9976851851851851\n",
      "ANN is better 0.9973544973544973\n",
      "RF vs. ANN: 0.9786324786324786 vs 0.9973544973544973\n",
      "RF is better 0.9979729729729729\n",
      "RF vs. ANN: 0.9979729729729729 vs 0.990410052910053\n",
      "ANN is better 0.9914021164021164\n",
      "RF vs. ANN: 0.9898550724637681 vs 0.9914021164021164\n",
      "RF is better 0.9859672569328433\n",
      "RF vs. ANN: 0.9859672569328433 vs 0.9748677248677248\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9935042735042735 vs 1.0\n",
      "ANN is better 0.9907407407407407\n",
      "RF vs. ANN: 0.9899350649350649 vs 0.9907407407407407\n",
      "ANN is better 0.986111111111111\n",
      "RF vs. ANN: 0.9845982851698952 vs 0.986111111111111\n",
      "RF is better 0.9823051948051948\n",
      "RF vs. ANN: 0.9823051948051948 vs 0.9821428571428571\n",
      "RF is better 0.9796921061251228\n",
      "RF vs. ANN: 0.9796921061251228 vs 0.9708994708994709\n",
      "RF is better 0.9927285318559557\n",
      "RF vs. ANN: 0.9927285318559557 vs 0.988095238095238\n",
      "RF is better 0.9819579017707986\n",
      "RF vs. ANN: 0.9819579017707986 vs 0.9794973544973544\n",
      "ANN is better 0.9957010582010583\n",
      "RF vs. ANN: 0.9895726495726496 vs 0.9957010582010583\n",
      "ANN is better 0.9914021164021164\n",
      "RF vs. ANN: 0.9775337837837839 vs 0.9914021164021164\n",
      "ANN is better 0.9963624338624338\n",
      "RF vs. ANN: 0.9948361823361823 vs 0.9963624338624338\n",
      "ANN is better 0.9993386243386244\n",
      "RF vs. ANN: 0.996031746031746 vs 0.9993386243386244\n",
      "RF is better 0.9945299145299145\n",
      "RF vs. ANN: 0.9945299145299145 vs 0.9821428571428571\n",
      "RF is better 0.9993243243243244\n",
      "RF vs. ANN: 0.9993243243243244 vs 0.9861111111111112\n",
      "ANN is better 0.9930555555555556\n",
      "RF vs. ANN: 0.990501146413364 vs 0.9930555555555556\n",
      "ANN is better 0.998015873015873\n",
      "RF vs. ANN: 0.984102564102564 vs 0.998015873015873\n",
      "RF is better 0.9976068376068377\n",
      "RF vs. ANN: 0.9976068376068377 vs 0.9841269841269841\n",
      "ANN is better 0.9963624338624338\n",
      "RF vs. ANN: 0.9796626984126985 vs 0.9963624338624338\n",
      "ANN is better 0.9983465608465608\n",
      "RF vs. ANN: 0.9853896103896104 vs 0.9983465608465608\n",
      "RF is better 0.9952922077922078\n",
      "RF vs. ANN: 0.9952922077922078 vs 0.9765211640211641\n",
      "RF is better 0.9835358056265985\n",
      "RF vs. ANN: 0.9835358056265985 vs 0.9742063492063492\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9886401603742064 vs 1.0\n",
      "ANN is better 0.9920634920634921\n",
      "RF vs. ANN: 0.9899145299145299 vs 0.9920634920634921\n",
      "ANN is better 0.9937169312169313\n",
      "RF vs. ANN: 0.9774930747922437 vs 0.9937169312169313\n",
      "ANN is better 0.9993386243386244\n",
      "RF vs. ANN: 0.9885470085470085 vs 0.9993386243386244\n",
      "RF is better 0.996031746031746\n",
      "RF vs. ANN: 0.996031746031746 vs 0.9877645502645503\n",
      "RF is better 0.9998268698060943\n",
      "RF vs. ANN: 0.9998268698060943 vs 0.9844576719576719\n",
      "RF is better 0.9970172684458398\n",
      "RF vs. ANN: 0.9970172684458398 vs 0.9900793650793651\n",
      "RF is better 0.9948849104859334\n",
      "RF vs. ANN: 0.9948849104859334 vs 0.9910714285714286\n",
      "RF is better 0.9978021978021978\n",
      "RF vs. ANN: 0.9978021978021978 vs 0.9751984126984127\n",
      "RF is better 1.0\n",
      "RF vs. ANN: 1.0 vs 0.9966931216931216\n",
      "ANN is better 0.9996693121693122\n",
      "RF vs. ANN: 0.9964062499999999 vs 0.9996693121693122\n",
      "ANN is better 0.9910714285714286\n",
      "RF vs. ANN: 0.9795608108108108 vs 0.9910714285714286\n",
      "RF is better 0.9924872122762148\n",
      "RF vs. ANN: 0.9924872122762148 vs 0.9864417989417988\n",
      "ANN is better 0.9880952380952381\n",
      "RF vs. ANN: 0.9873376623376624 vs 0.9880952380952381\n",
      "RF is better 0.991875\n",
      "RF vs. ANN: 0.991875 vs 0.9785052910052909\n",
      "RF is better 0.9968836565096952\n",
      "RF vs. ANN: 0.9968836565096952 vs 0.9894179894179893\n",
      "RF is better 0.9993558776167472\n",
      "RF vs. ANN: 0.9993558776167472 vs 0.9798280423280424\n",
      "RF is better 0.9926495155362512\n",
      "RF vs. ANN: 0.9926495155362512 vs 0.9828042328042328\n",
      "ANN is better 0.9976851851851852\n",
      "RF vs. ANN: 0.9916897506925207 vs 0.9976851851851852\n",
      "ANN is better 0.9970238095238095\n",
      "RF vs. ANN: 0.9844415329184408 vs 0.9970238095238095\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9893518518518519 vs 1.0\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9916475597772683 vs 1.0\n",
      "ANN is better 0.9963624338624338\n",
      "RF vs. ANN: 0.9869932432432432 vs 0.9963624338624338\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.9759253193580085 vs 0.9990079365079365\n",
      "ANN is better 0.998015873015873\n",
      "RF vs. ANN: 0.9934462915601022 vs 0.998015873015873\n",
      "ANN is better 0.9973544973544974\n",
      "RF vs. ANN: 0.9745299145299146 vs 0.9973544973544974\n",
      "RF is better 0.9989743589743589\n",
      "RF vs. ANN: 0.9989743589743589 vs 0.9966931216931216\n",
      "RF is better 0.9925324675324676\n",
      "RF vs. ANN: 0.9925324675324676 vs 0.9884259259259259\n",
      "ANN is better 0.998015873015873\n",
      "RF vs. ANN: 0.9871794871794872 vs 0.998015873015873\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.9797101449275362 vs 0.9990079365079365\n",
      "ANN is better 0.9976851851851852\n",
      "RF vs. ANN: 0.9784615384615384 vs 0.9976851851851852\n",
      "ANN is better 0.9986772486772486\n",
      "RF vs. ANN: 0.9780844155844156 vs 0.9986772486772486\n",
      "ANN is better 0.9755291005291005\n",
      "RF vs. ANN: 0.9707843759923785 vs 0.9755291005291005\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9975761772853186 vs 1.0\n",
      "ANN is better 0.9953703703703705\n",
      "RF vs. ANN: 0.9782470625595427 vs 0.9953703703703705\n",
      "ANN is better 0.9937169312169313\n",
      "RF vs. ANN: 0.9918628808864266 vs 0.9937169312169313\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9928571428571429 vs 1.0\n",
      "RF is better 0.9831081081081081\n",
      "RF vs. ANN: 0.9831081081081081 vs 0.9781746031746031\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.9788781163434903 vs 0.9990079365079365\n",
      "RF is better 0.995897435897436\n",
      "RF vs. ANN: 0.995897435897436 vs 0.9818121693121693\n",
      "ANN is better 0.9983465608465608\n",
      "RF vs. ANN: 0.9955541441727532 vs 0.9983465608465608\n",
      "ANN is better 0.994047619047619\n",
      "RF vs. ANN: 0.9842532467532468 vs 0.994047619047619\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9990530303030303 vs 1.0\n",
      "ANN is better 0.9917328042328043\n",
      "RF vs. ANN: 0.9843304843304843 vs 0.9917328042328043\n",
      "RF is better 0.9944805194805195\n",
      "RF vs. ANN: 0.9944805194805195 vs 0.9877645502645502\n",
      "RF is better 0.9986635482793184\n",
      "RF vs. ANN: 0.9986635482793184 vs 0.9907407407407407\n",
      "ANN is better 0.9970238095238095\n",
      "RF vs. ANN: 0.9829695767195766 vs 0.9970238095238095\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.9909375 vs 0.9990079365079365\n",
      "RF is better 0.9987297554779295\n",
      "RF vs. ANN: 0.9987297554779295 vs 0.9976851851851851\n",
      "ANN is better 0.9973544973544974\n",
      "RF vs. ANN: 0.9880952380952381 vs 0.9973544973544974\n",
      "ANN is better 0.9950396825396826\n",
      "RF vs. ANN: 0.9830332409972299 vs 0.9950396825396826\n",
      "RF is better 0.9946624803767661\n",
      "RF vs. ANN: 0.9946624803767661 vs 0.9927248677248677\n",
      "RF is better 0.9925595238095238\n",
      "RF vs. ANN: 0.9925595238095238 vs 0.9794973544973545\n",
      "ANN is better 0.9880952380952381\n",
      "RF vs. ANN: 0.9856410256410256 vs 0.9880952380952381\n",
      "ANN is better 0.9993386243386243\n",
      "RF vs. ANN: 0.9942028985507246 vs 0.9993386243386243\n",
      "RF is better 0.9958132045088567\n",
      "RF vs. ANN: 0.9958132045088567 vs 0.9871031746031745\n",
      "RF is better 0.9883116883116884\n",
      "RF vs. ANN: 0.9883116883116884 vs 0.9765211640211641\n",
      "RF is better 0.9972158532590895\n",
      "RF vs. ANN: 0.9972158532590895 vs 0.9914021164021164\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.9729773992793973 vs 0.9990079365079365\n",
      "ANN is better 0.9996693121693122\n",
      "RF vs. ANN: 0.9927939731411726 vs 0.9996693121693122\n",
      "RF is better 0.9986486486486487\n",
      "RF vs. ANN: 0.9986486486486487 vs 0.9943783068783069\n",
      "ANN is better 0.9963624338624338\n",
      "RF vs. ANN: 0.9926495155362512 vs 0.9963624338624338\n",
      "RF is better 0.9974025974025974\n",
      "RF vs. ANN: 0.9974025974025974 vs 0.9943783068783069\n",
      "RF is better 0.9965625\n",
      "RF vs. ANN: 0.9965625 vs 0.9947089947089947\n",
      "ANN is better 0.9920634920634921\n",
      "RF vs. ANN: 0.9865625 vs 0.9920634920634921\n",
      "ANN is better 0.9953703703703703\n",
      "RF vs. ANN: 0.9913043478260869 vs 0.9953703703703703\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9893547330494595 vs 1.0\n",
      "RF is better 0.9858455882352941\n",
      "RF vs. ANN: 0.9858455882352941 vs 0.9791666666666666\n",
      "RF is better 0.9923822714681441\n",
      "RF vs. ANN: 0.9923822714681441 vs 0.9788359788359788\n",
      "ANN is better 0.9910714285714286\n",
      "RF vs. ANN: 0.9894390581717453 vs 0.9910714285714286\n",
      "ANN is better 0.9966931216931216\n",
      "RF vs. ANN: 0.9754426996324758 vs 0.9966931216931216\n",
      "RF is better 0.9832951195545365\n",
      "RF vs. ANN: 0.9832951195545365 vs 0.9814814814814815\n",
      "RF is better 0.9974025974025974\n",
      "RF vs. ANN: 0.9974025974025974 vs 0.9907407407407407\n",
      "RF is better 0.9940325497287523\n",
      "RF vs. ANN: 0.9940325497287523 vs 0.9867724867724867\n",
      "RF is better 0.9928165720013364\n",
      "RF vs. ANN: 0.9928165720013364 vs 0.9814814814814815\n",
      "RF is better 0.9987297554779294\n",
      "RF vs. ANN: 0.9987297554779294 vs 0.9712301587301587\n",
      "ANN is better 0.996031746031746\n",
      "RF vs. ANN: 0.9900974025974026 vs 0.996031746031746\n",
      "ANN is better 0.9983465608465608\n",
      "RF vs. ANN: 0.9815878378378378 vs 0.9983465608465608\n",
      "ANN is better 0.9877645502645502\n",
      "RF vs. ANN: 0.9863449307893752 vs 0.9877645502645502\n",
      "ANN is better 0.9914021164021164\n",
      "RF vs. ANN: 0.9894255050505051 vs 0.9914021164021164\n",
      "RF is better 0.9894179894179894\n",
      "RF vs. ANN: 0.9894179894179894 vs 0.986441798941799\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.994286703601108 vs 0.9990079365079365\n",
      "RF is better 0.9973270965586368\n",
      "RF vs. ANN: 0.9973270965586368 vs 0.9957010582010581\n",
      "ANN is better 0.9993386243386244\n",
      "RF vs. ANN: 0.99203125 vs 0.9993386243386244\n",
      "RF is better 0.9969230769230768\n",
      "RF vs. ANN: 0.9969230769230768 vs 0.9927248677248677\n",
      "ANN is better 0.9811507936507937\n",
      "RF vs. ANN: 0.9727272727272728 vs 0.9811507936507937\n",
      "RF is better 0.9922958397534667\n",
      "RF vs. ANN: 0.9922958397534667 vs 0.9702380952380952\n",
      "RF is better 0.9806585677749361\n",
      "RF vs. ANN: 0.9806585677749361 vs 0.9715608465608465\n",
      "ANN is better 0.9996693121693122\n",
      "RF vs. ANN: 0.9823753572562719 vs 0.9996693121693122\n",
      "RF is better 0.998081841432225\n",
      "RF vs. ANN: 0.998081841432225 vs 0.9907407407407407\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.9956081081081082 vs 0.9990079365079365\n",
      "ANN is better 0.9894179894179894\n",
      "RF vs. ANN: 0.9648648648648648 vs 0.9894179894179894\n",
      "ANN is better 0.9963624338624338\n",
      "RF vs. ANN: 0.9898460530625613 vs 0.9963624338624338\n",
      "RF is better 0.9892029215624007\n",
      "RF vs. ANN: 0.9892029215624007 vs 0.9867724867724867\n",
      "RF is better 0.9940325497287522\n",
      "RF vs. ANN: 0.9940325497287522 vs 0.9917328042328042\n",
      "RF is better 0.9996537396121884\n",
      "RF vs. ANN: 0.9996537396121884 vs 0.9943783068783069\n",
      "ANN is better 0.9996693121693122\n",
      "RF vs. ANN: 0.9802873371199465 vs 0.9996693121693122\n",
      "ANN is better 0.9884259259259259\n",
      "RF vs. ANN: 0.9847402597402598 vs 0.9884259259259259\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9622222222222222 vs 1.0\n",
      "RF is better 0.9836309523809524\n",
      "RF vs. ANN: 0.9836309523809524 vs 0.9771825396825397\n",
      "ANN is better 0.9983465608465609\n",
      "RF vs. ANN: 0.9903124999999999 vs 0.9983465608465609\n",
      "RF is better 0.9928902116402116\n",
      "RF vs. ANN: 0.9928902116402116 vs 0.9722222222222221\n",
      "RF is better 0.9841524216524217\n",
      "RF vs. ANN: 0.9841524216524217 vs 0.9837962962962964\n",
      "RF is better 0.9899009146341463\n",
      "RF vs. ANN: 0.9899009146341463 vs 0.9811507936507936\n",
      "RF is better 0.999375\n",
      "RF vs. ANN: 0.999375 vs 0.9976851851851851\n",
      "ANN is better 0.9976851851851852\n",
      "RF vs. ANN: 0.9670584045584045 vs 0.9976851851851852\n",
      "ANN is better 0.9983465608465609\n",
      "RF vs. ANN: 0.986618444846293 vs 0.9983465608465609\n",
      "ANN is better 0.9976851851851851\n",
      "RF vs. ANN: 0.9898209898209898 vs 0.9976851851851851\n",
      "ANN is better 0.9937169312169313\n",
      "RF vs. ANN: 0.97390625 vs 0.9937169312169313\n",
      "RF is better 0.9983465608465608\n",
      "RF vs. ANN: 0.9983465608465608 vs 0.9781746031746031\n",
      "RF is better 0.99737962659679\n",
      "RF vs. ANN: 0.99737962659679 vs 0.9907407407407407\n",
      "ANN is better 0.998015873015873\n",
      "RF vs. ANN: 0.9898095556298028 vs 0.998015873015873\n",
      "RF is better 0.9935064935064936\n",
      "RF vs. ANN: 0.9935064935064936 vs 0.9933862433862433\n",
      "ANN is better 0.9993386243386244\n",
      "RF vs. ANN: 0.9824168797953964 vs 0.9993386243386244\n",
      "ANN is better 0.9904100529100529\n",
      "RF vs. ANN: 0.9864267676767676 vs 0.9904100529100529\n",
      "RF is better 0.9990338164251208\n",
      "RF vs. ANN: 0.9990338164251208 vs 0.9745370370370371\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9958132045088567 vs 1.0\n",
      "ANN is better 0.9990079365079365\n",
      "RF vs. ANN: 0.9846874999999999 vs 0.9990079365079365\n",
      "RF is better 0.9945436507936508\n",
      "RF vs. ANN: 0.9945436507936508 vs 0.9854497354497354\n",
      "ANN is better 0.998015873015873\n",
      "RF vs. ANN: 0.9869695957233545 vs 0.998015873015873\n",
      "ANN is better 1.0\n",
      "RF vs. ANN: 0.9811507936507936 vs 1.0\n",
      "ANN is better 0.998015873015873\n",
      "RF vs. ANN: 0.9894699894699894 vs 0.998015873015873\n",
      "RF is better 0.9849466463414633\n",
      "RF vs. ANN: 0.9849466463414633 vs 0.9821428571428571\n",
      "RF is better 0.9953703703703705\n",
      "RF vs. ANN: 0.9953703703703705 vs 0.9818121693121693\n",
      "RF is better 0.9938808373590983\n",
      "RF vs. ANN: 0.9938808373590983 vs 0.9871031746031746\n",
      "ANN is better 0.9910714285714286\n",
      "RF vs. ANN: 0.9836038961038961 vs 0.9910714285714286\n",
      "RF is better 0.9849662162162162\n",
      "RF vs. ANN: 0.9849662162162162 vs 0.9794973544973545\n",
      "ANN is better 0.9986772486772486\n",
      "RF vs. ANN: 0.9935810810810811 vs 0.9986772486772486\n",
      "RF is better 0.9966183574879227\n",
      "RF vs. ANN: 0.9966183574879227 vs 0.9917328042328042\n",
      "ANN is better 0.9940476190476191\n",
      "RF vs. ANN: 0.9748759305210918 vs 0.9940476190476191\n",
      "ANN is better 0.9950396825396826\n",
      "RF vs. ANN: 0.9873376623376624 vs 0.9950396825396826\n",
      "ANN is better 0.9983465608465609\n",
      "RF vs. ANN: 0.9915540540540541 vs 0.9983465608465609\n",
      "ANN is better 0.9907407407407407\n",
      "RF vs. ANN: 0.9854660875375877 vs 0.9907407407407407\n",
      "ANN is better 0.9983465608465608\n",
      "RF vs. ANN: 0.9945652173913044 vs 0.9983465608465608\n",
      "RF is better 0.995085995085995\n",
      "RF vs. ANN: 0.995085995085995 vs 0.9768518518518517\n",
      "ANN is better 0.9966931216931216\n",
      "RF vs. ANN: 0.9909060846560847 vs 0.9966931216931216\n",
      "ANN is better 0.9920634920634921\n",
      "RF vs. ANN: 0.9627464082860006 vs 0.9920634920634921\n",
      "ANN is better 0.9887566137566137\n",
      "RF vs. ANN: 0.9741048593350383 vs 0.9887566137566137\n",
      "ANN is better 0.9973544973544973\n",
      "RF vs. ANN: 0.9796419796419796 vs 0.9973544973544973\n",
      "RF is better 0.9928069053708439\n",
      "RF vs. ANN: 0.9928069053708439 vs 0.9818121693121693\n",
      "ANN is better 0.9930555555555555\n",
      "RF vs. ANN: 0.9765811965811967 vs 0.9930555555555555\n",
      "RF is better 0.9987373737373737\n",
      "RF vs. ANN: 0.9987373737373737 vs 0.9923941798941798\n",
      "ANN is better 0.9986772486772486\n",
      "RF vs. ANN: 0.9920634920634921 vs 0.9986772486772486\n",
      "ANN is better 0.9914021164021164\n",
      "RF vs. ANN: 0.9883760683760684 vs 0.9914021164021164\n",
      "ANN is better 0.9957010582010581\n",
      "RF vs. ANN: 0.9869727047146403 vs 0.9957010582010581\n",
      "ANN is better 0.9986772486772486\n",
      "RF vs. ANN: 0.994988306047444 vs 0.9986772486772486\n",
      "RF is better 0.9952365830422356\n",
      "RF vs. ANN: 0.9952365830422356 vs 0.9930555555555555\n",
      "RF is better 0.9930756843800322\n",
      "RF vs. ANN: 0.9930756843800322 vs 0.9828042328042328\n",
      "ANN is better 0.9904100529100529\n",
      "RF vs. ANN: 0.9734994734994735 vs 0.9904100529100529\n",
      "ANN is better 0.998015873015873\n",
      "RF vs. ANN: 0.9723721816449666 vs 0.998015873015873\n",
      "ANN is better 0.9976851851851851\n",
      "RF vs. ANN: 0.9801790281329923 vs 0.9976851851851851\n",
      "ANN is better 0.9927248677248677\n",
      "RF vs. ANN: 0.9742036011080332 vs 0.9927248677248677\n",
      "Totals rfwins: 85 \n",
      "equal 0 \n",
      "annwins 115 \n",
      "total 200\n",
      "how often a models AUC is better\n",
      "rf winrate: 0.425\n",
      "ann winrate: 0.575\n",
      "tie rate: 0.0\n",
      "\n",
      "Averages and standard deviations\n",
      "average RF auc: 0.9886740862049308 |std RF auc: 0.00798078460541243\n",
      "average ANN auc: 0.9911342592592592 |std ANN auc: 0.00779704053281621\n",
      "Accuracy measurements:\n",
      "average RF accuracy: 0.8360526315789474 |std RF accuracy0.12632306874737154 \n",
      "average ANN accuracy: 0.8426315789473684 |std ANN accuracy 0.1502118131058699\n",
      "\n",
      "average rf runtime: 0.24683489441871642 |std rf runtime: 0.007632643801155635\n",
      "average ann runtime: 3.4956585896015167 |std ann runtime: 0.5096218928297875\n",
      "total runtime: 748.6637229919434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "prog_start = time.time()\n",
    "data = pd.read_csv('breastcancer.csv') \n",
    "\n",
    "features_selected = ['radius_mean', 'texture_mean', 'smoothness_mean', 'compactness_mean', \n",
    "                     'concavity_mean', 'symmetry_mean', 'radius_se', 'concave points_se', \n",
    "                     'smoothness_worst', 'compactness_worst', 'concavity_worst', \n",
    "                     'symmetry_worst', 'fractal_dimension_worst'] # Features that were highly correlated when feature selection was done\n",
    "\n",
    "\n",
    "X1 = data[features_selected]\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})  # Convert labels to binary\n",
    "y1 = data['diagnosis']\n",
    "\n",
    "\n",
    "X1 = X1.dropna()\n",
    "y1 = y1.dropna()\n",
    "\n",
    "X1 = X1.loc[y1.index] # make sure X & y line up together\n",
    "RF_AUCs = []\n",
    "timerf = [] \n",
    "ac_rf = []\n",
    "for i in range(1,201):\n",
    "    rf_start = time.time()\n",
    "    random.seed(i)\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    #train test\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2)\n",
    "    \n",
    "    #define classifier with best parameters\n",
    "    rf = RandomForestClassifier(\n",
    "        bootstrap=False,\n",
    "        max_depth=None,\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=200\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train1, y_train1)\n",
    "    '''\n",
    "    #Feature importance\n",
    "    importance = rf.feature_importances_\n",
    "    \n",
    "    # Combine with feature names\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X1.columns,\n",
    "        'Importance': importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    print(feature_importance_df)\n",
    "    '''\n",
    "    #metrics for Random Forest\n",
    "    y_pred_probs_rf = rf.predict_proba(X_test1)[:,1] \n",
    "    roc_auc_rf = roc_auc_score(y_test1, y_pred_probs_rf)\n",
    "    \n",
    "    #roc and auc\n",
    "    fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test1, y_pred_probs_rf)\n",
    "    tpr_max_rf=tpr_rf.argmax()\n",
    "    best_thresh_rf=thresholds_rf[tpr_max_rf]\n",
    "    \n",
    "    #apply threshold to probabilities\n",
    "    y_pred_rf = (y_pred_probs_rf >= best_thresh_rf).astype(int) \n",
    "    timerf.append(time.time()-rf_start)\n",
    "    #gives accuracy precision F1 of pred vs test\n",
    "    ac_rf.append(accuracy_score(y_test1,y_pred_rf))\n",
    "    RF_AUCs.append(roc_auc_rf)\n",
    "\n",
    "######################################################-ANN-N############################################################\n",
    "X2 = data[features_selected]\n",
    "y2 = data['diagnosis']\n",
    "ANN_AUCs = []\n",
    "timea = []\n",
    "ac_ann = []\n",
    "for i in range(1,201):\n",
    "    a_start = time.time() \n",
    "    print(i)\n",
    "    random.seed(i)\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    # training and test sets\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, stratify=y2)\n",
    "    \n",
    "    # scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train2 = scaler.fit_transform(X_train2)\n",
    "    X_test2 = scaler.transform(X_test2)\n",
    "    \n",
    "    # ANN architechture\n",
    "    def create_model(learning_rate=0.001, dropout_rate=0.3):\n",
    "        model = Sequential([\n",
    "            Input(shape=(X_train2.shape[1],)),  # Input layer\n",
    "            Dense(64, activation='relu'),     # First hidden layer\n",
    "            Dropout(dropout_rate),            # Dropout for regularization\n",
    "            Dense(32, activation='relu'),     # Second hidden layer\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(1, activation='sigmoid')    # Output layer for binary classification\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    # initial lr and training \n",
    "    learning_rate = 0.001\n",
    "    dropout_rate = 0.3\n",
    "    model = create_model(learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train2, y_train2,\n",
    "        epochs=60,           \n",
    "        batch_size=32,       \n",
    "        validation_split=0.2,     \n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # metrics \n",
    "    #get probabilities from ANN\n",
    "    y_pred_probs_ANN = model.predict(X_test2).flatten()  \n",
    "    \n",
    "    #use probs with different threshold to develop ROC curve\n",
    "    fpr_ANN, tpr_ANN, thresholds_ANN = roc_curve(y_test2, y_pred_probs_ANN)\n",
    "    #calculate AUC of ROC\n",
    "    roc_auc_ANN = roc_auc_score(y_test2, y_pred_probs_ANN)\n",
    "    \n",
    "    #find best threshold and assign to model\n",
    "    tpr_max_ANN=tpr_ANN.argmax()\n",
    "    best_thresh_ANN=thresholds_ANN[tpr_max_ANN]\n",
    "    \n",
    "    #make binary predictions\n",
    "    y_pred_ANN = (y_pred_probs_ANN >= best_thresh_ANN).astype(int)\n",
    "    timea.append(time.time()-a_start)\n",
    "    ac_ann.append(accuracy_score(y_test2,y_pred_ANN))\n",
    "    ANN_AUCs.append(roc_auc_ANN)\n",
    "    \n",
    "####################################-COMPARE-##################\n",
    "total=0\n",
    "rfwin=0\n",
    "annwin=0\n",
    "equal=0\n",
    "for r, a in zip(RF_AUCs,ANN_AUCs):\n",
    "    if r > a:\n",
    "        rfwin += 1\n",
    "        print(f'RF is better {r}')\n",
    "    elif r == a:\n",
    "        equal += 1\n",
    "        print(\"equal\")\n",
    "    else:\n",
    "        annwin += 1\n",
    "        print(f'ANN is better {a}')\n",
    "    print(f'RF vs. ANN: {r} vs {a}')\n",
    "    total += 1\n",
    "print(f'Totals rfwins: {rfwin} \\nequal {equal} \\nannwins {annwin} \\ntotal {total}')\n",
    "rfwinP = rfwin/total\n",
    "annwinP = annwin/total\n",
    "equalP = equal/total\n",
    "print(\"how often a models AUC is better\")\n",
    "print(f'rf winrate: {rfwinP}')\n",
    "print(f'ann winrate: {annwinP}')\n",
    "print(f'tie rate: {equalP}\\n')\n",
    "\n",
    "print(f'Averages and standard deviations')\n",
    "print(f'average RF auc: {np.mean(RF_AUCs)} |std RF auc: {np.std(RF_AUCs)}')\n",
    "print(f'average ANN auc: {np.mean(ANN_AUCs)} |std ANN auc: {np.std(ANN_AUCs)}')\n",
    "rf_av = np.mean(ac_rf)\n",
    "rf_std = np.std(ac_rf)\n",
    "ann_av = np.mean(ac_ann)\n",
    "ann_std = np.std(ac_ann)\n",
    "print(f'Accuracy measurements:\\naverage RF accuracy: {rf_av} |std RF accuracy{rf_std} \\naverage ANN accuracy: {ann_av} |std ANN accuracy {ann_std}\\n')\n",
    "print(f'average rf runtime: {np.mean(timerf)} |std rf runtime: {np.std(timerf)}')\n",
    "print(f'average ann runtime: {np.mean(timea)} |std ann runtime: {np.std(timea)}')\n",
    "prog_total = time.time()-prog_start\n",
    "print(f'total runtime: {prog_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a80ce9-f0c3-4c0a-a523-953d1880f6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952e699-f052-4159-afd8-8e651ff7edc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
